## Задание 1:
Функции реализованы.

## Задание 2:
Метрики на модели TF-IDF:

- Recall@1: 0.4320
- Recall@3: 0.6121
- Recall@10: 0.7710
- MRR: 0.5401

## Задание 3:
Метрики на модели Multilingual-E5-Base:

- Recall@1: 0.7480
- Recall@3: 0.8976
- Recall@10: 0.9665
- MRR: 0.8284

## Задание 4:
Метрики после дообучения модели на Contrastive Loss и Triplet Loss:

- Recall@1: 0.2814
- Recall@3: 0.4148
- Recall@10: 0.5563
- MRR: 0.3647

## Задание 5:
Метрики для модели E5, дообученной с использованием Hard Negatives:

- Recall@1: 0.7405
- Recall@3: 0.8912
- Recall@10: 0.9632
- MRR: 0.8185

## Ответы на вопросы:

### Задание 2:
1. Метрики получились достаточно низкими, что может говорить о некоторых ограничениях алгоритма TF-IDF, таких как игнорирование контекста и семантики.
2. Ограничения подхода: TF-IDF не учитывает контекст, а только частоту слов, что ограничивает его эффективность в случае с похожими, но разными словами.

### Задание 3:
1. Метрики значительно улучшились, что связано с использованием предобученной модели Multilingual-E5-Base, которая лучше захватывает семантику текста.
2. Улучшения произошли, так как модель E5 использует глубокое понимание контекста и отношений между словами, в отличие от TF-IDF.

### Задание 4:
1. Метрики улучшились по сравнению с TF-IDF, но хуже, чем на модели E5.
2. Влияние Loss-функций: Triplet Loss показал лучшие результаты, так как работает с тройками данных, лучше обучая модель на различении похожих и непохожих документов.

### Задание 5:
1. Метрики показали улучшение по сравнению с случайными негативными примерами, что подтверждает эффективность использования Hard Negatives для более точного обучения модели.
2. Улучшение по сравнению с random negatives объясняется тем, что Hard Negatives позволяют модели учиться на более сложных примерах, которые ближе к реальным задачам.

