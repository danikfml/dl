
## Результаты экспериментов

### Эксперимент 1: train1.py
- **Архитектура и параметры:**  
  - `hidden_size = 32`, 1 базовый блок, без skip connections и dropout.  
  - Оптимизатор: SGD, lr = 0.01, weight_decay = 0.0, batch_size = 32, 10 эпох.
- **Результаты:**  
  - **Epoch 10:**  
    - Обучение: Loss = 0.2077, AUROC = 0.9166  
    - Валидация: Loss = 0.1892, AUROC = 0.9298  
- **Пояснение:**  
  Базовая модель демонстрирует стабильное снижение ошибки и рост ROC-AUC. Результаты на валидации (AUROC ≈ 0.93) подтверждают, что модель уже способна различать положительные и отрицательные случаи

---

### Эксперимент 2: train2.py
- **Архитектура и параметры:**  
  - `hidden_size = 128`, 3 базовых блока, без skip connections и dropout.  
  - Остальные гиперпараметры: lr = 0.01, weight_decay = 0.0, batch_size = 32, 10 эпох.
- **Результаты:**  
  - **Epoch 10:**  
    - Обучение: Loss = 0.1905, AUROC = 0.9264  
    - Валидация: Loss = 0.1739, AUROC = 0.9372  
- **Пояснение:**  
  Увеличение числа нейронов и слоёв привело к снижению ошибки и повышению ROC-AUC (до ~0.937 на валидации). Это свидетельствует о том, что более мощная модель способна лучше захватывать сложные зависимости, хотя риск переобучения возрастает.

---

### Эксперимент 3: train3.py
- **Архитектура и параметры:**  
  - Структура аналогична эксперименту 2 (`hidden_size = 128`, 3 блока), но в базовом блоке добавлены улучшения (например, skip connections и BatchNorm).
- **Результаты:**  
  - **Epoch 10:**  
    - Обучение: Loss = 0.1940, AUROC = 0.9243  
    - Валидация: Loss = 0.1840, AUROC = 0.9353  
- **Пояснение:**  
  Дополнительные архитектурные улучшения обеспечили более стабильное обучение. Несмотря на незначительное отличие в метриках по сравнению с экспериментом 2, такие изменения способствуют лучшей устойчивости и позволяют модели сохранять качество при увеличении глубины.

---

### Эксперимент 4: train4.py
- **Архитектура и параметры:**  
  - Базовая архитектура аналогична эксперименту 2, но добавлен Dropout (например, dropout_p ≈ 0.2).  
  - Обучение проводилось дольше (до 20 эпох).
- **Результаты:**  
  - Ранние эпохи показывают более высокие значения функции потерь и ниже AUROC, однако к 20-й эпохе показатели стабилизируются: валидационный AUROC находится примерно в диапазоне 0.930–0.932.
- **Пояснение:**  
  Применение Dropout помогает снизить переобучение, что подтверждается уменьшением разницы между метриками на обучении и валидации. Однако слишком агрессивный Dropout может замедлить сходимость, поэтому оптимальное значение (примерно 0.2) является компромиссным вариантом.

---

### Эксперимент 5: train5.py
- **Архитектура и параметры:**  
  - Используется архитектура, аналогичная экспериментам 2–3 (hidden_size = 128, 3 блока) с Dropout (как в эксперименте 4).  
  - Проводился перебор гиперпараметров: весовой штраф (weight_decay, например, 0.001) и изменение скорости обучения (например, lr от 0.01 до 0.1).  
  - Обучение проводилось 20 эпох.
- **Результаты:**  
  - **Epoch 20:**  
    - Обучение: Loss ≈ 0.2009, AUROC ≈ 0.9185  
    - Валидация: Loss ≈ 0.1797, AUROC ≈ 0.9353  
- **Пояснение:**  
  Тонкая настройка гиперпараметров оптимизатора (learning rate и weight decay) улучшила обобщающую способность модели. Небольшой весовой штраф и правильно подобранная скорость обучения обеспечили стабильную сходимость и валидационный AUROC на уровне ≈ 0.935, что свидетельствует о хорошем балансе между переобучением и недообучением.

---

