# WebFAQ Retrieval → Rerank: отчёт по эксперименту

## 1. Постановка задачи
Цель — построить двухступенчатую систему поиска ответа на русском языке на базе датасета WebFAQ:
1) **Retrieval**: дообучить трансформер-энкодер (bi-encoder) на задачу dense retrieval.
2) **Reranking**: дообучить кросс-энкодер (query+passage) и переупорядочить топ-кандидатов.
3) Измерить качество на валидации и сравнить «до» и «после» реранка.

## 2. Датасет
- **WebFAQ-retrieval** (PaDaS-Lab). Формат: корпус `corpus.jsonl`, запросы `queries-*.jsonl`, релевантности `qrels-*.jsonl`.
- Язык: русский. Каждому запросу соответствует один или несколько релевантных пасседжей.
- Метрики считаются на отложенной выборке.

## 3. Метод
### 3.1. Bi-encoder (Retrieval)
- Модель: `intfloat/multilingual-e5-small`.
- Обучение: MultipleNegativesRankingLoss (in-batch negatives), 1 эпоха, адаптивный батч с уменьшением при OOM.
- Токенизация: `max_seq_length`≈128 c префиксами **query:**/**passage:**.
- Индексация: FAISS `IndexFlatIP` по L2-нормированным эмбеддингам.

### 3.2. Cross-encoder (Reranking)
- Базовый вариант: `BAAI/bge-reranker-v2-m3`. При недостатке VRAM — компактный фоллбек `ai-forever/ruBert-tiny2`.
- Обучение: BCEWithLogitsLoss на парах (положительный релевант + hard-negative), тёплый старт (~20%), градиентная аккумуляция.
- Ограничение длины: 96–128, авто-уменьшение при OOM.

### 3.3. Конвейер
1) Кодирование корпуса → FAISS.
2) Поиск top-k (k=20) кандидатов bi-энкодером.
3) Реранк top-k кросс-энкодером.
4) Подсчёт метрик @10.

## 4. Экспериментальные настройки (ключевое)
- Объём пар для bi-encoder: ≈6000.
- Кросс-энкодер: ≈6000 примеров (1 pos + 1 hard-neg на запрос).
- `rerank_topk`: 20. `k` для метрик: 10.
- GPU: авто-снижение batch/max_len; при OOM — фоллбек.

## 5. Результаты
### 5.1. Сводные метрики (@10)
| Система | R@10 | MRR@10 | nDCG@10 |
|---|---:|---:|---:|
| Bi-encoder | 0.2497 | 0.2036 | 0.2147 |
| Retrieve→Rerank | 0.2589 | 0.2246 | 0.2329 |

### 5.2. Интерпретация
- **R@10**: +0.0092 — реранкер слегка повысил долю запросов с «попаданием» в топ‑10.
- **MRR@10 / nDCG@10**: рост значительнее: реранкер поднимает релевант выше в списке.

## 6. Выводы
- Двухступенчатая схема на WebFAQ подтверждает эффективность: добавление реранка улучшает **MRR@10** и **nDCG@10** на ~8–10% относительных, а **R@10** — умеренно.
- При ограниченной памяти GPU компактный кросс-энкодер остаётся практичным способом улучшить точность без существенного роста времени индексации/поиска.

## 7. Источники данных
- WebFAQ-retrieval: https://huggingface.co/datasets/PaDaS-Lab/webfaq-retrieval
